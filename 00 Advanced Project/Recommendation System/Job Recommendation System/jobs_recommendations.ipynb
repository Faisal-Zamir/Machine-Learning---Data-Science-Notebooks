{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4ac767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load datasets\n",
    "# postings = pd.read_csv(\"Jobs Data/postings.csv\")\n",
    "# job_skills = pd.read_csv(\"Jobs Data/job_skills.csv\")\n",
    "# skills = pd.read_csv(\"Jobs Data/skills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf1f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd1eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_skills.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6169d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028adfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Merge job_skills with skill names\n",
    "# job_skills_full = job_skills.merge(skills, on=\"skill_abr\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e70b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78551d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_skills_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb54a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aggregate skills per job\n",
    "# skills_per_job = job_skills_full.groupby(\"job_id\")[\"skill_name\"].apply(lambda x: \" \".join(x)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f341398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_per_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f4df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge aggregated skills into postings\n",
    "# jobs_combined = postings.merge(skills_per_job, on=\"job_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c90b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25c3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Columns to drop\n",
    "# cols_to_drop = [\n",
    "#     'max_salary', 'pay_period', 'company_id', 'views', 'med_salary', \n",
    "#     'min_salary', 'formatted_work_type', 'applies', 'original_listed_time', \n",
    "#     'remote_allowed', 'job_posting_url', 'application_url', 'application_type', \n",
    "#     'expiry', 'closed_time', 'skills_desc', 'listed_time', 'posting_domain', \n",
    "#     'sponsored', 'work_type', 'currency', 'compensation_type', 'normalized_salary', \n",
    "#     'zip_code', 'fips', 'company_name'\n",
    "# ]\n",
    "\n",
    "# # Drop columns\n",
    "# jobs_filtered = jobs_combined.drop(columns=cols_to_drop)\n",
    "\n",
    "# # Save updated DataFrame to new CSV\n",
    "# jobs_filtered.to_csv(\"jobs_filtered.csv\", index=False)\n",
    "\n",
    "# print(\"Updated jobs CSV saved as 'jobs_filtered.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16744c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Jobs_filtered = pd.read_csv(\"jobs_filtered.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2c6c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id                         0.000000\n",
      "title                          0.000000\n",
      "description                    0.005652\n",
      "location                       0.000000\n",
      "formatted_experience_level    23.745852\n",
      "skill_name                     1.415433\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Percentage of missing values per column\n",
    "missing_percent = Jobs_filtered.isnull().sum() / len(Jobs_filtered) * 100\n",
    "print(missing_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a99274e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   job_id                      123849 non-null  int64 \n",
      " 1   title                       123849 non-null  object\n",
      " 2   description                 123842 non-null  object\n",
      " 3   location                    123849 non-null  object\n",
      " 4   formatted_experience_level  94440 non-null   object\n",
      " 5   skill_name                  122096 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "Jobs_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c848a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "formatted_experience_level\n",
       "Mid-Senior level    41489\n",
       "Entry level         36708\n",
       "Associate            9826\n",
       "Director             3746\n",
       "Internship           1449\n",
       "Executive            1222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs_filtered['formatted_experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82175ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill small missing text columns with empty strings\n",
    "Jobs_filtered['description'] = Jobs_filtered['description'].fillna('')\n",
    "Jobs_filtered['skill_name'] = Jobs_filtered['skill_name'].fillna('')\n",
    "\n",
    "# For experience level, you can:\n",
    "# Option 1: Replace missing with 'Not Specified'\n",
    "Jobs_filtered['formatted_experience_level'] = Jobs_filtered['formatted_experience_level'].fillna('Not Specified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e679dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jobs_filtered['combined_text'] = (\n",
    "    Jobs_filtered['title'].astype(str) + ' ' +\n",
    "    Jobs_filtered['description'].astype(str) + ' ' +\n",
    "    Jobs_filtered['location'].astype(str) + ' ' +\n",
    "    Jobs_filtered['formatted_experience_level'].astype(str) + ' ' +\n",
    "    Jobs_filtered['skill_name'].astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2727157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Faisal\n",
      "[nltk_data]     Zamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Faisal\n",
      "[nltk_data]     Zamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (only once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation / special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. contractions \n",
    "    text = contractions.fix(text)   # <-- handle contractions here can’t to cannot\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # 4. Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join words back to string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply to your column\n",
    "Jobs_filtered['Document_Cleaned'] = Jobs_filtered['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d7651f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(Jobs_filtered[\"Document_Cleaned\"])  # return sparse matrix (SciPy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546d0e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (123849, 5000)\n",
      "['aa' 'aaa' 'ab' ... 'zip' 'zone' 'zoom']\n"
     ]
    }
   ],
   "source": [
    "# Get feature names (vocabulary)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"TF-IDF shape:\", tfidf_matrix.shape)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2831ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abreast</th>\n",
       "      <th>absence</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa   ab  aba  abide   ability  able  abreast  absence  abuse  ...  \\\n",
       "0  0.0  0.0  0.0  0.0    0.0  0.000000   0.0      0.0      0.0    0.0  ...   \n",
       "1  0.0  0.0  0.0  0.0    0.0  0.022639   0.0      0.0      0.0    0.0  ...   \n",
       "2  0.0  0.0  0.0  0.0    0.0  0.000000   0.0      0.0      0.0    0.0  ...   \n",
       "3  0.0  0.0  0.0  0.0    0.0  0.000000   0.0      0.0      0.0    0.0  ...   \n",
       "4  0.0  0.0  0.0  0.0    0.0  0.000000   0.0      0.0      0.0    0.0  ...   \n",
       "\n",
       "   yield      york  young  youth  youtube        yr  zero  zip  zone  zoom  \n",
       "0    0.0  0.000000    0.0    0.0      0.0  0.000000   0.0  0.0   0.0   0.0  \n",
       "1    0.0  0.000000    0.0    0.0      0.0  0.000000   0.0  0.0   0.0   0.0  \n",
       "2    0.0  0.000000    0.0    0.0      0.0  0.000000   0.0  0.0   0.0   0.0  \n",
       "3    0.0  0.058318    0.0    0.0      0.0  0.000000   0.0  0.0   0.0   0.0  \n",
       "4    0.0  0.000000    0.0    0.0      0.0  0.265185   0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out() \n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# See top rows\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa4bafb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>job_title</th>\n",
       "      <th>skills</th>\n",
       "      <th>preferred_industry</th>\n",
       "      <th>location</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>education_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Faisal Zamir</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Python, Scikit-learn, TensorFlow, NLP</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Islamabad, PK</td>\n",
       "      <td>3</td>\n",
       "      <td>Masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sara Ahmed</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>HTML, CSS, JavaScript, React, PHP</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Lahore, PK</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ali Khan</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Python, Pandas, SQL, ML, Statistics</td>\n",
       "      <td>AI Research</td>\n",
       "      <td>Karachi, PK</td>\n",
       "      <td>6</td>\n",
       "      <td>Masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ayesha Noor</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Android Developer</td>\n",
       "      <td>Java, Kotlin, Android Studio, Firebase</td>\n",
       "      <td>Mobile Development</td>\n",
       "      <td>Rawalpindi, PK</td>\n",
       "      <td>4</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hassan Raza</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Excel, SQL, PowerBI, Python</td>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Faisalabad, PK</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          name experience_level                  job_title  \\\n",
       "0        1  Faisal Zamir              Mid  Machine Learning Engineer   \n",
       "1        2    Sara Ahmed            Entry              Web Developer   \n",
       "2        3      Ali Khan           Senior             Data Scientist   \n",
       "3        4   Ayesha Noor              Mid          Android Developer   \n",
       "4        5   Hassan Raza            Entry               Data Analyst   \n",
       "\n",
       "                                   skills      preferred_industry  \\\n",
       "0   Python, Scikit-learn, TensorFlow, NLP  Information Technology   \n",
       "1       HTML, CSS, JavaScript, React, PHP    Software Development   \n",
       "2     Python, Pandas, SQL, ML, Statistics             AI Research   \n",
       "3  Java, Kotlin, Android Studio, Firebase      Mobile Development   \n",
       "4             Excel, SQL, PowerBI, Python      Business Analytics   \n",
       "\n",
       "         location  years_experience education_level  \n",
       "0   Islamabad, PK                 3         Masters  \n",
       "1      Lahore, PK                 1       Bachelors  \n",
       "2     Karachi, PK                 6         Masters  \n",
       "3  Rawalpindi, PK                 4       Bachelors  \n",
       "4  Faisalabad, PK                 2       Bachelors  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = pd.read_csv(\"user_profiles.csv\")\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff9dbae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Machine Learning Engineer Python, Scikit-learn...\n",
       "1    Web Developer HTML, CSS, JavaScript, React, PH...\n",
       "2    Data Scientist Python, Pandas, SQL, ML, Statis...\n",
       "3    Android Developer Java, Kotlin, Android Studio...\n",
       "4    Data Analyst Excel, SQL, PowerBI, Python Entry...\n",
       "5    Frontend Developer JavaScript, React, Vue, HTM...\n",
       "6    DevOps Engineer AWS, Docker, Kubernetes, CI/CD...\n",
       "7    QA Tester Selenium, Python, Manual Testing, Au...\n",
       "8    Backend Developer Python, Django, REST API, SQ...\n",
       "9    Business Analyst Excel, SQL, PowerBI, Data Ana...\n",
       "Name: profile_text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert numeric experience into text\n",
    "user_data[\"experience_text\"] = user_data[\"years_experience\"].astype(str) + \" years experience\"\n",
    "\n",
    "# Combine all user info into one text column\n",
    "user_data[\"profile_text\"] = (\n",
    "    user_data[\"job_title\"].fillna('') + \" \" +\n",
    "    user_data[\"skills\"].fillna('') + \" \" +\n",
    "    user_data[\"experience_level\"].fillna('') + \" \" +\n",
    "    user_data[\"experience_text\"].fillna('') + \" \" +\n",
    "    user_data[\"preferred_industry\"].fillna('') + \" \" +\n",
    "    user_data[\"education_level\"].fillna('') + \" \" +\n",
    "    user_data[\"location\"].fillna('')\n",
    ")\n",
    "user_data['profile_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "742e3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Faisal\n",
      "[nltk_data]     Zamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Faisal\n",
      "[nltk_data]     Zamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (only once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation / special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. contractions \n",
    "    text = contractions.fix(text)   # <-- handle contractions here can’t to cannot\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # 4. Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join words back to string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply to your column\n",
    "user_data['Profile_Cleaned'] = user_data['profile_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc80261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tfidf = vectorizer.transform(user_data[\"Profile_Cleaned\"]) # return sparse matrix (SciPy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two vector table : Document_Cleaned and Profile Cleaned (user_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cfbc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61886c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 123849)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Marketing Coordinator</th>\n",
       "      <th>Mental Health Therapist/Counselor</th>\n",
       "      <th>Assitant Restaurant Manager</th>\n",
       "      <th>Senior Elder Law / Trusts and Estates Associate Attorney</th>\n",
       "      <th>Service Technician</th>\n",
       "      <th>Economic Development and Planning Intern</th>\n",
       "      <th>Producer</th>\n",
       "      <th>Building Engineer</th>\n",
       "      <th>Respiratory Therapist</th>\n",
       "      <th>Worship Leader</th>\n",
       "      <th>...</th>\n",
       "      <th>Catering Event Manager</th>\n",
       "      <th>Phlebotomist - Float</th>\n",
       "      <th>Senior Frontend/App Developer</th>\n",
       "      <th>Account Manager, Client Success</th>\n",
       "      <th>Quality Engineer</th>\n",
       "      <th>Title IX/Investigations Attorney</th>\n",
       "      <th>Staff Software Engineer, ML Serving Platform</th>\n",
       "      <th>Account Executive, Oregon/Washington</th>\n",
       "      <th>Business Development Manager</th>\n",
       "      <th>Marketing Social Media Specialist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Faisal Zamir</th>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.034806</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>0.014559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.033450</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.050867</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.062804</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sara Ahmed</th>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.255885</td>\n",
       "      <td>0.014386</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.010083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ali Khan</th>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.020298</td>\n",
       "      <td>0.078175</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.034346</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.389872</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.010745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ayesha Noor</th>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.018209</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.297183</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.004364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hassan Raza</th>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.051424</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.060040</td>\n",
       "      <td>0.021217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123849 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title         Marketing Coordinator  Mental Health Therapist/Counselor  \\\n",
       "name                                                                     \n",
       "Faisal Zamir               0.007345                           0.008328   \n",
       "Sara Ahmed                 0.005640                           0.003302   \n",
       "Ali Khan                   0.005558                           0.000000   \n",
       "Ayesha Noor                0.004330                           0.002535   \n",
       "Hassan Raza                0.007814                           0.000000   \n",
       "\n",
       "title         Assitant Restaurant Manager  \\\n",
       "name                                        \n",
       "Faisal Zamir                     0.006852   \n",
       "Sara Ahmed                       0.005262   \n",
       "Ali Khan                         0.005185   \n",
       "Ayesha Noor                      0.004040   \n",
       "Hassan Raza                      0.007289   \n",
       "\n",
       "title         Senior Elder Law / Trusts and Estates Associate Attorney  \\\n",
       "name                                                                     \n",
       "Faisal Zamir                                           0.006851          \n",
       "Sara Ahmed                                             0.005261          \n",
       "Ali Khan                                               0.024232          \n",
       "Ayesha Noor                                            0.004039          \n",
       "Hassan Raza                                            0.007289          \n",
       "\n",
       "title          Service Technician  Economic Development and Planning Intern  \\\n",
       "name                                                                          \n",
       "Faisal Zamir             0.033168                                  0.004532   \n",
       "Sara Ahmed               0.004509                                  0.023719   \n",
       "Ali Khan                 0.004443                                  0.020298   \n",
       "Ayesha Noor              0.003462                                  0.018209   \n",
       "Hassan Raza              0.019454                                  0.017261   \n",
       "\n",
       "title         Producer  Building Engineer  Respiratory Therapist  \\\n",
       "name                                                               \n",
       "Faisal Zamir  0.034806           0.059167               0.013007   \n",
       "Sara Ahmed    0.003151           0.006593               0.004346   \n",
       "Ali Khan      0.078175           0.006497               0.002924   \n",
       "Ayesha Noor   0.002419           0.005062               0.003337   \n",
       "Hassan Raza   0.004365           0.011747               0.004111   \n",
       "\n",
       "title         Worship Leader  ...  Catering Event Manager  \\\n",
       "name                          ...                           \n",
       "Faisal Zamir        0.014559  ...                0.007406   \n",
       "Sara Ahmed          0.001979  ...                0.005687   \n",
       "Ali Khan            0.001951  ...                0.005604   \n",
       "Ayesha Noor         0.001520  ...                0.004366   \n",
       "Hassan Raza         0.002742  ...                0.007879   \n",
       "\n",
       "title         Phlebotomist - Float  Senior Frontend/App Developer  \\\n",
       "name                                                                \n",
       "Faisal Zamir              0.010381                       0.033450   \n",
       "Sara Ahmed                0.015124                       0.255885   \n",
       "Ali Khan                  0.007856                       0.034346   \n",
       "Ayesha Noor               0.006120                       0.297183   \n",
       "Hassan Raza               0.020953                       0.031277   \n",
       "\n",
       "title         Account Manager, Client Success  Quality Engineer  \\\n",
       "name                                                              \n",
       "Faisal Zamir                         0.017473          0.050867   \n",
       "Sara Ahmed                           0.014386          0.006472   \n",
       "Ali Khan                             0.014417          0.006378   \n",
       "Ayesha Noor                          0.057848          0.004969   \n",
       "Hassan Raza                          0.051424          0.008967   \n",
       "\n",
       "title         Title IX/Investigations Attorney  \\\n",
       "name                                             \n",
       "Faisal Zamir                          0.008319   \n",
       "Sara Ahmed                            0.013376   \n",
       "Ali Khan                              0.006296   \n",
       "Ayesha Noor                           0.010269   \n",
       "Hassan Raza                           0.017378   \n",
       "\n",
       "title         Staff Software Engineer, ML Serving Platform  \\\n",
       "name                                                         \n",
       "Faisal Zamir                                      0.062804   \n",
       "Sara Ahmed                                        0.009859   \n",
       "Ali Khan                                          0.389872   \n",
       "Ayesha Noor                                       0.002443   \n",
       "Hassan Raza                                       0.026981   \n",
       "\n",
       "title         Account Executive, Oregon/Washington  \\\n",
       "name                                                 \n",
       "Faisal Zamir                              0.019499   \n",
       "Sara Ahmed                                0.020170   \n",
       "Ali Khan                                  0.014570   \n",
       "Ayesha Noor                               0.011702   \n",
       "Hassan Raza                               0.026247   \n",
       "\n",
       "title         Business Development Manager  Marketing Social Media Specialist  \n",
       "name                                                                           \n",
       "Faisal Zamir                      0.000000                           0.015573  \n",
       "Sara Ahmed                        0.011744                           0.010083  \n",
       "Ali Khan                          0.004479                           0.010745  \n",
       "Ayesha Noor                       0.009016                           0.004364  \n",
       "Hassan Raza                       0.060040                           0.021217  \n",
       "\n",
       "[5 rows x 123849 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_sim.shape)\n",
    "# Convert to DataFrame\n",
    "similarity_df = pd.DataFrame(\n",
    "    cosine_sim,\n",
    "    index=user_data[\"name\"],         # user names as rows\n",
    "    columns=Jobs_filtered[\"title\"]   # job titles as columns\n",
    ")\n",
    "\n",
    "# Show first few users vs jobs\n",
    "similarity_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed1f1be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 jobs for Faisal Zamir:\n",
      "Index(['Developer', 'Senior Machine Learning Engineer',\n",
      "       'Machine Learning Engineer - Remote',\n",
      "       'Machine Learning Engineer - Remote',\n",
      "       'Machine Learning Engineer - Remote'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Sara Ahmed:\n",
      "Index(['React Developer', 'Vue Developer', 'Javascript Developer',\n",
      "       'Senior Front End Developer with Vue JS experience',\n",
      "       'React Developer (Only W2)'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Ali Khan:\n",
      "Index(['Analyst', 'Senior Data Scientist',\n",
      "       'Sr. Data Scientist - IoT and Manufacturing',\n",
      "       'Senior Machine Learning Engineer', 'Python Developer'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Ayesha Noor:\n",
      "Index(['Android Developer', 'Android Developer', 'Lead Android Developer ',\n",
      "       'Senior Android Developer - Remote / Telecommute', 'Android Developer'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Hassan Raza:\n",
      "Index(['Data Analyst',\n",
      "       'Python Developer (Python 3.0 or above, Django, Flask, Angular/React/Vue/JavaScript, Python Libraries (Panda/NumPy/Sci-kit), SQL and PL/SQL)',\n",
      "       'Senior Data Analyst- Scientist', 'Data Quality & Analytics AVP ',\n",
      "       'Technology Analyst'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Maryam Khan:\n",
      "Index(['Unpaid Front-end Developer Intern', 'Expert React Frontend Developer',\n",
      "       'Senior Frontend Developer', 'Founding Front-End Engineer (Web)',\n",
      "       'Frontend Developer React'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Bilal Ahmed:\n",
      "Index(['DevOps Engineer', ' Senior Software Engineer - Kubernetes (1927890)',\n",
      "       'AWS Cloud Infrastructure and DevOps Technical SME', 'DevOps Engineer',\n",
      "       'AWS Cloud Infrastructure and DevOps Technical SME'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Zara Ali:\n",
      "Index(['Quality Assurance Tester', 'QA Tester', 'Manual Tester',\n",
      "       'Junior Level QA Tester Role', 'Manual Tester'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Usman Sheikh:\n",
      "Index(['GoLang Developer (Capital One Experience Required) - ***W2 Only***',\n",
      "       'Python Developer', 'Back End Developer', 'Python Developer',\n",
      "       'Node.JS Backend Developer'],\n",
      "      dtype='object', name='title')\n",
      "\n",
      "Top 5 jobs for Sana Iqbal:\n",
      "Index(['Business Analyst III', 'Data Quality & Analytics AVP ',\n",
      "       'Business Data Analyst', 'Business Analyst IV',\n",
      "       'Business Analytics Associate'],\n",
      "      dtype='object', name='title')\n"
     ]
    }
   ],
   "source": [
    "for i, user in enumerate(similarity_df.index):\n",
    "    top_indices = similarity_df.iloc[i].sort_values(ascending=False).head(5).index\n",
    "    print(f\"\\nTop 5 jobs for {user}:\")\n",
    "    print(top_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91f89313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Select Faisal Zamir's similarity scores\n",
    "user_similarities = similarity_df.head().loc[\"Faisal Zamir\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbd08861",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_jobs = user_similarities.sort_values(ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e073a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Job Title  Similarity Score\n",
      "0                           Developer          0.460730\n",
      "1    Senior Machine Learning Engineer          0.440024\n",
      "2  Machine Learning Engineer - Remote          0.437329\n",
      "3  Machine Learning Engineer - Remote          0.437287\n",
      "4  Machine Learning Engineer - Remote          0.435892\n"
     ]
    }
   ],
   "source": [
    "top_5_df = top_5_jobs.reset_index()\n",
    "top_5_df.columns = ['Job Title', 'Similarity Score']\n",
    "print(top_5_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6a73b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Save the essential components\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(tfidf_matrix, \"jobs_tfidf_matrix.pkl\")\n",
    "\n",
    "# Save the job data for reference\n",
    "Jobs_filtered[['title', 'description', 'location', 'formatted_experience_level', 'skill_name']].to_pickle(\"jobs_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01f11134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all saved components\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "jobs_tfidf_matrix = joblib.load(\"jobs_tfidf_matrix.pkl\")\n",
    "jobs_data = pd.read_pickle(\"jobs_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26fe308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new unseen user data\n",
    "new_user = pd.DataFrame({\n",
    "    \"name\": [\"Ali Raza\"],\n",
    "    \"job_title\": [\"Data Analyst\"],\n",
    "    \"skills\": [\"Python, SQL, Excel, Power BI\"],\n",
    "    \"experience_level\": [\"Entry\"],\n",
    "    \"years_experience\": [1],\n",
    "    \"preferred_industry\": [\"Information Technology\"],\n",
    "    \"location\": [\"Lahore, PK\"],\n",
    "    \"education_level\": [\"Bachelors\"]\n",
    "})\n",
    "\n",
    "# Combine into one text\n",
    "new_user[\"experience_text\"] = new_user[\"years_experience\"].astype(str) + \" years experience\"\n",
    "new_user[\"profile_text\"] = (\n",
    "    new_user[\"job_title\"] + \" \" +\n",
    "    new_user[\"skills\"] + \" \" +\n",
    "    new_user[\"experience_level\"] + \" \" +\n",
    "    new_user[\"experience_text\"] + \" \" +\n",
    "    new_user[\"preferred_industry\"] + \" \" +\n",
    "    new_user[\"education_level\"] + \" \" +\n",
    "    new_user[\"location\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afb38f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = contractions.fix(text)\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "new_user[\"Profile_Cleaned\"] = new_user[\"profile_text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c18e2655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top job recommendations for Ali Raza:\n",
      "\n",
      "title\n",
      "Data Analyst - Power BI & SQL    0.600978\n",
      "BI Analyst                       0.599566\n",
      "Power BI Architect               0.570967\n",
      "Power BI Developer               0.562427\n",
      "Senior PowerBi Designer          0.553911\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert using existing TF-IDF vectorizer\n",
    "new_user_tfidf = vectorizer.transform(new_user[\"Profile_Cleaned\"])\n",
    "\n",
    "# Calculate cosine similarity with job TF-IDF matrix\n",
    "cosine_sim_new = cosine_similarity(new_user_tfidf, tfidf_matrix)\n",
    "\n",
    "# Get top 5 matching jobs\n",
    "similarity_series = pd.Series(cosine_sim_new[0], index=Jobs_filtered[\"title\"])\n",
    "top_5 = similarity_series.sort_values(ascending=False).head(5)\n",
    "\n",
    "# Display\n",
    "print(f\"\\nTop job recommendations for {new_user['name'][0]}:\\n\")\n",
    "print(top_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9857acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_jobs(user_profile_dict):\n",
    "#     # Load pickled models\n",
    "#     with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "#         vectorizer = pickle.load(f)\n",
    "#     with open(\"tfidf_matrix.pkl\", \"rb\") as f:\n",
    "#         tfidf_matrix = pickle.load(f)\n",
    "#     with open(\"jobs_filtered.pkl\", \"rb\") as f:\n",
    "#         Jobs_filtered = pickle.load(f)\n",
    "\n",
    "#     # Create user DataFrame\n",
    "#     user_df = pd.DataFrame([user_profile_dict])\n",
    "#     user_df[\"experience_text\"] = user_df[\"years_experience\"].astype(str) + \" years experience\"\n",
    "#     user_df[\"profile_text\"] = (\n",
    "#         user_df[\"job_title\"] + \" \" +\n",
    "#         user_df[\"skills\"] + \" \" +\n",
    "#         user_df[\"experience_level\"] + \" \" +\n",
    "#         user_df[\"experience_text\"] + \" \" +\n",
    "#         user_df[\"preferred_industry\"] + \" \" +\n",
    "#         user_df[\"education_level\"] + \" \" +\n",
    "#         user_df[\"location\"]\n",
    "#     )\n",
    "\n",
    "#     user_df[\"Profile_Cleaned\"] = user_df[\"profile_text\"].apply(preprocess_text)\n",
    "\n",
    "#     # Vectorize and compute similarity\n",
    "#     user_vec = vectorizer.transform(user_df[\"Profile_Cleaned\"])\n",
    "#     cosine_sim = cosine_similarity(user_vec, tfidf_matrix)[0]\n",
    "\n",
    "#     # Find top 5 jobs\n",
    "#     top_jobs = pd.Series(cosine_sim, index=Jobs_filtered[\"title\"]).sort_values(ascending=False).head(5)\n",
    "#     return top_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_jobs({\n",
    "#     \"name\": \"Ali Raza\",\n",
    "#     \"job_title\": \"Data Analyst\",\n",
    "#     \"skills\": \"Python, SQL, Excel, Power BI\",\n",
    "#     \"experience_level\": \"Entry\",\n",
    "#     \"years_experience\": 1,\n",
    "#     \"preferred_industry\": \"Information Technology\",\n",
    "#     \"location\": \"Lahore, PK\",\n",
    "#     \"education_level\": \"Bachelors\"\n",
    "# })\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
